{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('Continuum': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "12214a5209b2b38696f6b602f083d2bf1938889f648fd24b82338554fb0cec82"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import MultiTagger\n",
    "from flair.models import TextClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-03-08 00:06:08,846 loading file C:\\Users\\e0185181\\.flair\\models\\en-chunk-conll2000-fast-v0.4.pt\n",
      "2021-03-08 00:06:09,214 loading file C:\\Users\\e0185181\\.flair\\models\\en-pos-ontonotes-fast-v0.5.pt\n"
     ]
    }
   ],
   "source": [
    "# load the 'chunk' and POS taggers\n",
    "tagger = MultiTagger.load(['chunk-fast', 'pos-fast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-03-08 01:37:01,945 loading file C:\\Users\\e0185181\\.flair\\models\\sentiment-en-mix-distillbert_3.1.pt\n"
     ]
    }
   ],
   "source": [
    "# load sentiment tagger\n",
    "classifier = TextClassifier.load('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sentence\n",
    "# text = 'I love Bamboo HR, but I really hate interviews.'\n",
    "# text = 'I think she is really cool but maybe too cool'\n",
    "text = 'I like the Samsung smart watch because it is sleek and durable'\n",
    "sentence = Sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run NER over sentence\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentence: \"I like the Samsung smart watch because it is sleek and durable\"   [− Tokens: 12  − Token-Labels: \"I <S-NP/PRP> like <S-VP/VBP> the <B-NP/DT> Samsung <I-NP/NNP> smart <I-NP/JJ> watch <E-NP/NN> because <S-SBAR/IN> it <S-NP/PRP> is <S-VP/VBZ> sleek <B-ADJP/JJ> and <I-ADJP/CC> durable <E-ADJP/JJ>\"]\n"
     ]
    }
   ],
   "source": [
    "# check prediction\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conjunctions(sentence):\n",
    "    pos = [span.tag for span in sentence.get_spans('pos-fast')]\n",
    "    has_conjunction = 'CC' in pos\n",
    "    breaks = []\n",
    "    if has_conjunction:\n",
    "        for i, val in enumerate(pos):\n",
    "            if val == 'CC':\n",
    "                breaks.append(i)\n",
    "    return breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "breaks = get_conjunctions(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['PRP', 'VBP', 'NNP', 'NNP', ',', 'CC', 'PRP', 'RB', 'VBP', 'NNS', '.']\n",
      "True\n",
      "[10]\n"
     ]
    }
   ],
   "source": [
    "print(pos)\n",
    "print(has_conjunction)\n",
    "print(breaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_spans(spans):\n",
    "    text = [text.to_original_text() for text in spans]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = []\n",
    "spans = sentence.get_spans('pos-fast')\n",
    "current_break = 0\n",
    "\n",
    "for next_cc in breaks:\n",
    "    before_cc = spans[current_break:next_cc]\n",
    "    cc = spans[next_cc]\n",
    "    parts.append({'type': 'phrase', 'text': combine_spans(before_cc)})\n",
    "    parts.append({'type': 'conjunction', 'text': cc.text})\n",
    "    current_break = next_cc\n",
    "\n",
    "last_part = spans[breaks[-1]+1:]\n",
    "parts.append({'type': 'phrase', 'text': combine_spans(last_part)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'type': 'phrase',\n",
       "  'text': 'I like the Samsung smart watch because it is sleek'},\n",
       " {'type': 'conjunction', 'text': 'and'},\n",
       " {'type': 'phrase', 'text': 'durable'}]"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in parts:\n",
    "    if part['type'] == 'phrase':\n",
    "        sentence = Sentence(part['text'])\n",
    "        classifier.predict(sentence)\n",
    "        part['sentiment'] = sentence.to_dict()['labels'][0]['value']\n",
    "        part['labels'] = sentence.to_dict()['labels'][0]['confidence']\n",
    "    if part['type'] == 'conjunction':\n",
    "        if part['text'] in ('but'):\n",
    "            part['reverse'] = True\n",
    "        elif part['text'] in ('and', 'or'):\n",
    "            part['reverse'] = False\n",
    "        else:\n",
    "            part['reverse'] = None\n",
    "            print('Error.. unknown conjunction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'type': 'phrase',\n",
       "  'text': 'I like the Samsung smart watch because it is sleek',\n",
       "  'sentiment': 'POSITIVE',\n",
       "  'labels': 0.9975072741508484},\n",
       " {'type': 'conjunction', 'text': 'and', 'reverse': False},\n",
       " {'type': 'phrase',\n",
       "  'text': 'durable',\n",
       "  'sentiment': 'POSITIVE',\n",
       "  'labels': 0.999009370803833}]"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "hello=termcolor.colored('Hello World!', color='green', on_color='on_grey')\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore\n",
    "print(Fore.RED + 'Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}