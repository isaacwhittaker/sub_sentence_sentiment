{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference pipeline (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import MultiTagger\n",
    "from flair.models import TextClassifier\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-11 07:37:38,686 --------------------------------------------------------------------------------\n",
      "2021-03-11 07:37:38,688 The model key 'chunk-fast' now maps to 'https://huggingface.co/flair/chunk-english-fast' on the HuggingFace ModelHub\n",
      "2021-03-11 07:37:38,690  - The most current version of the model is automatically downloaded from there.\n",
      "2021-03-11 07:37:38,691  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/chunk-fast/en-chunk-conll2000-fast-v0.4.pt)\n",
      "2021-03-11 07:37:38,692 --------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6118c6203b47ebac92ada1d2f0521e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/75.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-11 07:38:10,072 loading file /Users/ike/.flair/models/chunk-english-fast/be3a207f4993dd6d174d5083341a717d371ec16f721358e7a4d72158ebab28a6.a7f897d05c83e618a8235bbb7ddfca5a79d2daefb8a97c776eb73f97dbaea508\n",
      "2021-03-11 07:38:11,679 --------------------------------------------------------------------------------\n",
      "2021-03-11 07:38:11,680 The model key 'pos-fast' now maps to 'https://huggingface.co/flair/pos-english-fast' on the HuggingFace ModelHub\n",
      "2021-03-11 07:38:11,681  - The most current version of the model is automatically downloaded from there.\n",
      "2021-03-11 07:38:11,684  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/pos-fast/en-pos-ontonotes-fast-v0.5.pt)\n",
      "2021-03-11 07:38:11,685 --------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6978aa1867404df295b437639909d844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/75.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-11 07:38:41,082 loading file /Users/ike/.flair/models/pos-english-fast/36f7923039eed4c66e4275927daaff6cd275997d61d238355fb1fe0338fe10a1.ff87e5b4e47fdb42a0c00237d9506c671db773e0a7932179ace82e584383a1b8\n"
     ]
    }
   ],
   "source": [
    "# load the 'chunk' and POS taggers\n",
    "tagger = MultiTagger.load(['chunk-fast', 'pos-fast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-11 07:38:43,166 https://nlp.informatik.hu-berlin.de/resources/models/sentiment-curated-distilbert/sentiment-en-mix-distillbert_4.pt not found in cache, downloading to /var/folders/qx/wpls85r17mg43_mg7lys9h9w0000gs/T/tmpuhjzuqwx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265512723/265512723 [03:57<00:00, 1117355.02B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-11 07:42:41,400 copying /var/folders/qx/wpls85r17mg43_mg7lys9h9w0000gs/T/tmpuhjzuqwx to cache at /Users/ike/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-11 07:42:43,254 removing temp file /var/folders/qx/wpls85r17mg43_mg7lys9h9w0000gs/T/tmpuhjzuqwx\n",
      "2021-03-11 07:42:43,430 loading file /Users/ike/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb25c24d38544ac69f2ec60553675623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead959169cf14b158ee751483cbaea12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load sentiment tagger\n",
    "classifier = TextClassifier.load('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sentence\n",
    "text = 'I love Bamboo HR, but I really hate interviews.'\n",
    "# text = 'I think she is really cool but maybe too cool'\n",
    "# text = 'I like the Samsung smart watch because it is sleek and durable'\n",
    "sentence = Sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run NER over sentence\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"I love Bamboo HR , but I really hate interviews .\"   [− Tokens: 11  − Token-Labels: \"I <S-NP/PRP> love <S-VP/VBP> Bamboo <B-NP/NNP> HR <E-NP/NNP> , <,> but <CC> I <S-NP/PRP> really <S-ADVP/RB> hate <S-VP/VBP> interviews <S-NP/NNS> . <.>\"]\n"
     ]
    }
   ],
   "source": [
    "# check prediction\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conjunctions(sentence):\n",
    "    pos = [span.tag for span in sentence.get_spans('pos-fast')]\n",
    "    has_conjunction = 'CC' in pos\n",
    "    breaks = []\n",
    "    if has_conjunction:\n",
    "        for i, val in enumerate(pos):\n",
    "            if val == 'CC':\n",
    "                breaks.append(i)\n",
    "    return pos, has_conjunction, breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, has_conjunction, breaks = get_conjunctions(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRP', 'VBP', 'NNP', 'NNP', ',', 'CC', 'PRP', 'RB', 'VBP', 'NNS', '.']\n",
      "True\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "print(pos)\n",
    "print(has_conjunction)\n",
    "print(breaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_spans(spans):\n",
    "    text = [text.to_original_text() for text in spans]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = []\n",
    "spans = sentence.get_spans('pos-fast')\n",
    "current_break = 0\n",
    "\n",
    "for next_cc in breaks:\n",
    "    before_cc = spans[current_break:next_cc]\n",
    "    cc = spans[next_cc]\n",
    "    parts.append({'type': 'phrase', 'text': combine_spans(before_cc)})\n",
    "    parts.append({'type': 'conjunction', 'text': cc.text})\n",
    "    current_break = next_cc\n",
    "\n",
    "last_part = spans[breaks[-1]+1:]\n",
    "parts.append({'type': 'phrase', 'text': combine_spans(last_part)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'phrase', 'text': 'I love Bamboo HR ,'},\n",
       " {'type': 'conjunction', 'text': 'but'},\n",
       " {'type': 'phrase', 'text': 'I really hate interviews .'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in parts:\n",
    "    if part['type'] == 'phrase':\n",
    "        sentence = Sentence(part['text'])\n",
    "        classifier.predict(sentence)\n",
    "        part['sentiment'] = sentence.to_dict()['labels'][0]['value']\n",
    "        part['labels'] = sentence.to_dict()['labels'][0]['confidence']\n",
    "    if part['type'] == 'conjunction':\n",
    "        if part['text'] in ('but'):\n",
    "            part['reverse'] = True\n",
    "        elif part['text'] in ('and', 'or'):\n",
    "            part['reverse'] = False\n",
    "        else:\n",
    "            part['reverse'] = None\n",
    "            print('Error.. unknown conjunction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'phrase',\n",
       "  'text': 'I love Bamboo HR ,',\n",
       "  'sentiment': 'POSITIVE',\n",
       "  'labels': 0.9989123344421387},\n",
       " {'type': 'conjunction', 'text': 'but', 'reverse': True},\n",
       " {'type': 'phrase',\n",
       "  'text': 'I really hate interviews .',\n",
       "  'sentiment': 'NEGATIVE',\n",
       "  'labels': 0.9963917136192322}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_text(parts):\n",
    "    output = ''\n",
    "    for part in parts:\n",
    "        if ('sentiment' in part.keys()) and (part['sentiment'] == 'POSITIVE'):\n",
    "            output += Fore.GREEN + part['text'] + ' [' +  str(round(part['labels'], 3)) + ']'\n",
    "        elif 'sentiment' in part.keys() and (part['sentiment'] == 'NEGATIVE'):\n",
    "            output += Fore.RED + part['text'] + ' [' +  str(round(part['labels'], 3)) + ']'\n",
    "        else:\n",
    "            output += Fore.BLACK + part['text']\n",
    "        output += ' '\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mI love Bamboo HR , [0.999] \u001b[30mbut \u001b[31mI really hate interviews . [0.996] \n"
     ]
    }
   ],
   "source": [
    "print(color_text(parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
